{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NCDPI 2018-2019 Raw Datasets\n",
    "### This program downloads all original datasets from www.ncpublicschools.org and saves them as .csv files. These data files are used to create all the flattened and machine learning datasets within the NCEA repository.\n",
    "\n",
    "1. This notebook downloads raw datasets directly from NCDPI specific URLs.\n",
    "2. Each raw dataset is filtered by school year and saved in the original layout as a .csv file.\n",
    "3. For consistency, both the Year and School code fields are renamed to \"year\" and \"agency_code\" in all files.\n",
    "4. All masking is removed from raw data fields using the following code: replace({\"*\":0, \">95\":100, \"<5\":0, \"<10\":5 })\n",
    "5. All * or carriage returns are removed from column names.\n",
    "6. All raw datasets created by this program are used to create the \"flattened\" and \"machine learning\" Public School datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#**********************************************************************************\n",
    "# Set the following variables before running this code!!!\n",
    "#**********************************************************************************\n",
    "\n",
    "#Location where copies of the raw data files will be downloaded and saved as csv files.\n",
    "#'C:/Users/Jake/Documents/GitHub/EducationDataNC/2018/Raw Datasets/'\n",
    "dataDir = 'D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/January 2020/2019/Raw Datasets/'\n",
    "\n",
    "#All raw data files are filtered for the year below\n",
    "schoolYear = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original SRC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os \n",
    "\n",
    "#Download and save an original copy of the raw SRC data \n",
    "url=\"https://files.nc.gov/dpi/src_datasets.zip\"\n",
    "zipFilePath = dataDir + 'src-datasets.zip'\n",
    "\n",
    "#Comment out the next line after downloading the original data one time! \n",
    "#urllib.request.urlretrieve(url, zipFilePath)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#Extract the zip file and all school datasets to the //Raw Datasets/ folder\n",
    "zip_ref = zipfile.ZipFile(zipFilePath, 'r')\n",
    "zip_ref.extractall(dataDir + 'SRC_Datasets/')\n",
    "zip_ref.close()\n",
    "\n",
    "#Remove corrupt file\n",
    "os.remove(dataDir + 'SRC_Datasets/' + \"rcd_acc_pc.xlsx\")\n",
    "#Remove Lookup Tables\n",
    "os.remove(dataDir + 'SRC_Datasets/' + \"rcd_ap_crs_list.xlsx\")\n",
    "os.remove(dataDir + 'SRC_Datasets/' + \"rcd_cte_enrollment_cluster.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Delete corrupt record from rcd_sat.xlsx\n",
    "filePath = dataDir + 'SRC_Datasets/' + 'rcd_sat.xlsx'\n",
    "rcdSat = pd.read_excel(filePath, dtype={'agency_code': object})\n",
    "rcdSat = rcdSat[rcdSat.year != '/*20']\n",
    "\n",
    "#Save file without the bold column headings\n",
    "import pandas.io.formats.excel\n",
    "pandas.io.formats.excel.header_style = None\n",
    "rcdSat.to_excel(filePath,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Most Recent Year of Data from Each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use ntpath.basename to get a filename from a filepath\n",
    "import ntpath\n",
    "\n",
    "def CleanUpRcdFiles(filePath):\n",
    "    fileName = ntpath.basename(filePath)\n",
    "    fileName = fileName.replace('xlsx','csv')\n",
    "    schFile = pd.read_excel(filePath, dtype={'agency_code': object, 'year':int})\n",
    "    maxYear = schFile['year'].max()\n",
    "    \n",
    "    #Filter records for the most recent year\n",
    "    schFile = schFile[schFile['year'] == maxYear]\n",
    "    \n",
    "    #Remove state and district level summary records \n",
    "    #schFile = schFile[(schFile['agency_code'] != 'NC-SEA') & (schFile['agency_code'].str.contains(\"LEA\") == False)]\n",
    "        \n",
    "    #Remove * character from any fields. \n",
    "    schFile = schFile.replace({'*':''})\n",
    "    schFile.to_csv(dataDir + 'SRC_Datasets/' + fileName, sep=',', index=False)\n",
    "    \n",
    "    print(fileName + ', Max Year: ' + str(maxYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Files to: D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/January 2020/2019/Raw Datasets/\n",
      "\n",
      "rcd_acc_aapart.csv, Max Year: 2019\n",
      "rcd_acc_act.csv, Max Year: 2019\n",
      "rcd_acc_awa.csv, Max Year: 2019\n",
      "rcd_acc_cgr.csv, Max Year: 2019\n",
      "rcd_acc_eds.csv, Max Year: 2019\n",
      "rcd_acc_eg.csv, Max Year: 2019\n",
      "rcd_acc_elp.csv, Max Year: 2019\n",
      "rcd_acc_essa_desig.csv, Max Year: 2019\n",
      "rcd_acc_gp.csv, Max Year: 2019\n",
      "rcd_acc_irm.csv, Max Year: 2019\n",
      "rcd_acc_lowperf.csv, Max Year: 2019\n",
      "rcd_acc_ltg.csv, Max Year: 2019\n",
      "rcd_acc_ltg_detail.csv, Max Year: 2019\n",
      "rcd_acc_mcr.csv, Max Year: 2019\n",
      "rcd_acc_part.csv, Max Year: 2019\n",
      "rcd_acc_part_detail.csv, Max Year: 2019\n",
      "rcd_acc_rta.csv, Max Year: 2019\n",
      "rcd_acc_spg1.csv, Max Year: 2017\n",
      "rcd_acc_spg2.csv, Max Year: 2019\n",
      "rcd_acc_wk.csv, Max Year: 2019\n",
      "rcd_ap.csv, Max Year: 2019\n",
      "rcd_charter.csv, Max Year: 2019\n",
      "rcd_courses2.csv, Max Year: 2019\n",
      "rcd_cte_concentrators.csv, Max Year: 2019\n",
      "rcd_cte_credentials.csv, Max Year: 2019\n",
      "rcd_cte_endorsement.csv, Max Year: 2019\n",
      "rcd_cte_enrollment.csv, Max Year: 2019\n",
      "rcd_dlmi.csv, Max Year: 2019\n",
      "rcd_ib.csv, Max Year: 2019\n",
      "rcd_inc1.csv, Max Year: 2017\n",
      "rcd_inc2.csv, Max Year: 2019\n",
      "rcd_location.csv, Max Year: 2019\n",
      "rcd_prin_demo.csv, Max Year: 2019\n",
      "rcd_readiness.csv, Max Year: 2019\n",
      "rcd_sat.csv, Max Year: 2019\n",
      "rcd_welcome.csv, Max Year: 2019\n"
     ]
    }
   ],
   "source": [
    "#Use wildcards to find files in a directory\n",
    "import glob\n",
    "import os\n",
    "#Get and display a list of all .csv file names for 2019 download\n",
    "rcdFiles = glob.glob(dataDir + 'SRC_Datasets/' + 'rcd*.xlsx')\n",
    "\n",
    "print('Saving Files to: ' + dataDir + '\\n')\n",
    "\n",
    "for filePth in rcdFiles:\n",
    "    fileName = ntpath.basename(filePth)\n",
    "    #if fileName != 'rcd_code_desc.csv': --No rcd_code_desc in the 2019 rcd files \n",
    "    CleanUpRcdFiles(filePth)\n",
    "    #Remove the old xlsx file since we converted it to csv\n",
    "    if os.path.exists(filePth):\n",
    "        os.remove(filePth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the Raw Data Files\n",
    "### This section reads raw data files directly from the \\\\Raw Datasets folder and flattens each file.\n",
    "1. Each agency_code could represent National, State, District, Or School Campus level data.\n",
    "2. This code creates new data columns using pivots until there is only one record per agency_code.\n",
    "3. Percentage fields are typically used for pivot values in cases where count, denominators, or percentages are available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PivotCsv(dataDir, fileName, pivValues, pivIndex, pivColumns, colSuffix):\n",
    "    pivFile = pd.read_csv(dataDir + fileName, low_memory=False, dtype={pivIndex: object})\n",
    "    \n",
    "    pivFile = pd.pivot_table(pivFile, values=pivValues,index=pivIndex,columns=pivColumns)\n",
    "    \n",
    "    #concatenate multiindex column names using a list comprehension.\n",
    "    pivFile.columns = [ '_'.join(str(i) for i in col) + colSuffix for col in pivFile.columns]\n",
    "\n",
    "    #Make our index a column for merges later\n",
    "    pivFile.reset_index(level=0, inplace=True)\n",
    "    return pivFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use table pivots to flatten each dataset\n",
    "* Each dataset is converted to one record per agency code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir = dataDir + 'SRC_Datasets/'\n",
    "\n",
    "#Pivot File - rcd_161 - Missing in 2019\n",
    "#rcd_161 = PivotCsv(srcDir, 'rcd_161.csv',['ccc_pct'],'agency_code', ['status','subgroup'],'_161')\n",
    "\n",
    "#Pivot File - rcd_acc_aapart \n",
    "rcd_acc_aapart = PivotCsv(srcDir, 'rcd_acc_aapart.csv',['pct'],'agency_code', ['subject','grade'],'_AAPART')\n",
    "\n",
    "#Pivot File - rcd_acc_act \n",
    "rcd_acc_act = PivotCsv(srcDir, 'rcd_acc_act.csv',['pct'],'agency_code', ['subject','subgroup'],'_ACT')\n",
    "\n",
    "#Pivot File - rcd_acc_awa \n",
    "rcd_acc_awa = PivotCsv(srcDir, 'rcd_acc_awa.csv',['pct'],'agency_code', ['subgroup'],'_AWA')\n",
    "\n",
    "#Pivot File - rcd_acc_cgr\n",
    "rcd_acc_cgr = PivotCsv(srcDir, 'rcd_acc_cgr.csv',['pct'],'agency_code', ['cgr_type', 'subgroup'],'_CGR')\n",
    "\n",
    "#File - rcd_acc_eds\n",
    "rcd_acc_eds = pd.read_csv(srcDir + 'rcd_acc_eds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_eds = rcd_acc_eds[['agency_code', 'pct_eds']]\n",
    "\n",
    "#Pivot File - rcd_acc_elp\n",
    "rcd_acc_elp = PivotCsv(srcDir, 'rcd_acc_elp.csv',['pct'],'agency_code', ['subgroup'],'_ELP')\n",
    "\n",
    "#File - rcd_acc_essa_desig\n",
    "rcd_acc_essa_desig = pd.read_csv(srcDir + 'rcd_acc_essa_desig.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_essa_desig.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_gp\n",
    "rcd_acc_gp = pd.read_csv(srcDir + 'rcd_acc_gp.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_gp.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_irm\n",
    "rcd_acc_irm = PivotCsv(srcDir, 'rcd_acc_irm.csv',['pct_prof'],'agency_code', ['grade'],'gr_irm')\n",
    "\n",
    "#File - rcd_acc_lowperf\n",
    "rcd_acc_lowperf = pd.read_csv(srcDir + 'rcd_acc_lowperf.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_lowperf = rcd_acc_lowperf[['agency_code', 'lp_school','rlp_school','clpc_school']]\n",
    "\n",
    "#Pivot File - rcd_acc_ltg\n",
    "rcd_acc_ltg = PivotCsv(srcDir, 'rcd_acc_ltg.csv',['pct_met'],'agency_code', ['target'],'_LTG')\n",
    "\n",
    "#File - rcd_acc_ltg_detail\n",
    "rcd_acc_ltg_detail = pd.read_csv(srcDir + 'rcd_acc_ltg_detail.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_ltg_detail.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_mcr\n",
    "rcd_acc_mcr = PivotCsv(srcDir, 'rcd_acc_mcr.csv',['pct'],'agency_code', ['subgroup'],'_MCR')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_part = PivotCsv(srcDir, 'rcd_acc_part.csv',['pct_met'],'agency_code', ['target'],'_PART')\n",
    "\n",
    "#Pivot File - rcd_acc_part\n",
    "rcd_acc_part_detail = PivotCsv(srcDir, 'rcd_acc_part_detail.csv',['pct'],'agency_code', ['target','subgroup'],'_PART_DET')\n",
    "\n",
    "#Pivot File - rcd_acc_pc - WARNING 3323 columns!!! - Missing in 2019\n",
    "#rcd_acc_pc = PivotCsv(srcDir, 'rcd_acc_pc.csv',['pct'],'agency_code', ['standard','subject','grade','subgroup'],'_PC')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_rta = PivotCsv(srcDir, 'rcd_acc_rta.csv',['pct'],'agency_code', ['metric'],'_RTA')\n",
    "\n",
    "#File - rcd_acc_spg1\n",
    "rcd_acc_spg1 = pd.read_csv(srcDir + 'rcd_acc_spg1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_spg1.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_spg2\n",
    "pivVals = ['aaa_score','awa_score','cgrs_score','elp_score','mcr_score','scgs_score','bi_score',\n",
    "           'ach_score','eg_status','eg_score','spg_score','spg_grade']\n",
    "           \n",
    "rcd_acc_spg2 = PivotCsv(srcDir, 'rcd_acc_spg2.csv',pivVals,'agency_code', ['subgroup'],'_SPG2')\n",
    "\n",
    "#Pivot File - rcd_acc_wk\n",
    "rcd_acc_wk = PivotCsv(srcDir, 'rcd_acc_wk.csv',['pct'],'agency_code', ['subgroup'],'_WK')\n",
    "\n",
    "#File - rcd_adm - Missing in 2019\n",
    "#rcd_adm = pd.read_csv(srcDir + 'rcd_adm.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_adm.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_ap\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_ap = pd.read_csv(srcDir + 'rcd_ap.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ap.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_arts - Missing in 2019\n",
    "#rcd_arts = pd.read_csv(srcDir + 'rcd_arts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_arts.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_att - Missing in 2019\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "#rcd_att = pd.read_csv(srcDir + 'rcd_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_charter\n",
    "rcd_charter = PivotCsv(srcDir, 'rcd_charter.csv',['pct_enrolled'],'agency_code', ['home_lea','subgroup'],'_CHARTER')\n",
    "\n",
    "#Pivot File - rcd_chronic_absent - Missing in 2019\n",
    "#rcd_chronic_absent = PivotCsv(srcDir, 'rcd_chronic_absent.csv',['pct'],'agency_code', ['subgroup'],'_CHRON_ABSENT')\n",
    "\n",
    "#Pivot File - rcd_college - Missing in 2019\n",
    "#rcd_college = PivotCsv(srcDir, 'rcd_college.csv',['pct_enrolled'],'agency_code', ['status','subgroup'],'_COLLEGE')\n",
    "\n",
    "#File - rcd_courses1 - 2017 DATA - Missing in 2019\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "#rcd_courses1 = pd.read_csv(srcDir + 'rcd_courses1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_courses1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_courses2\n",
    "rcd_courses2 = PivotCsv(srcDir, 'rcd_courses2.csv',['pct_ap','pct_ccp','pct_ib'],'agency_code', ['category_code','subgroup'],\n",
    "                        '_COURSES2')\n",
    "\n",
    "#Pivot File - rcd_cte_concentrators\n",
    "rcd_cte_concentrators = PivotCsv(srcDir, 'rcd_cte_concentrators.csv',['num_concentrators'],'agency_code',\n",
    "                                 ['career_cluster'],'')\n",
    "\n",
    "#File - rcd_cte_credentials\n",
    "rcd_cte_credentials = pd.read_csv(srcDir + 'rcd_cte_credentials.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_credentials.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_endorsement\n",
    "rcd_cte_endorsement = pd.read_csv(srcDir + 'rcd_cte_endorsement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_endorsement.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_enrollment\n",
    "rcd_cte_enrollment = pd.read_csv(srcDir + 'rcd_cte_enrollment.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_enrollment['cte_enrollment_pct'] = rcd_cte_enrollment['pct'] \n",
    "rcd_cte_enrollment.drop(['year','pct'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_dlmi\n",
    "rcd_dlmi = pd.read_csv(srcDir + 'rcd_dlmi.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_dlmi.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_effectiveness - 2017 Data - Missing in 2019\n",
    "#rcd_effectiveness = PivotCsv(srcDir, 'rcd_effectiveness.csv',['pct_rating'],'agency_code', ['ee_standard','ee_rating'],'')\n",
    "\n",
    "#File - rcd_esea_att - 2015 DATA - Missing in 2019\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "#rcd_esea_att = pd.read_csv(srcDir + 'rcd_esea_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_esea_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_experience- Missing in 2019\n",
    "#expPivColumns = ['pct_experience_0','pct_experience_10','pct_experience_4',\n",
    "#                 'pct_adv_degree','pct_turnover','total_class_teach','avg_class_teach']\n",
    "#rcd_experience = PivotCsv(srcDir, 'rcd_experience.csv',expPivColumns,'agency_code', ['staff'],'Exp')\n",
    "\n",
    "#File - !!!DISTRICT LEVEL DATA!!! - Missing in 2019\n",
    "#rcd_funds = pd.read_csv(srcDir + 'rcd_funds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_funds.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_hqt - !!!2016 DATA!!! - Missing in 2019 \n",
    "#rcd_hqt = PivotCsv(srcDir, 'rcd_hqt.csv',['highqual_class_pct'],'agency_code', ['category_code'],'')\n",
    "\n",
    "#File - rcd_ib\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_ib = pd.read_csv(srcDir + 'rcd_ib.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ib.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_improvement - Missing in 2019\n",
    "#rcd_improvement = PivotCsv(srcDir, 'rcd_improvement.csv',['amount'],'agency_code', ['strategy'],'_Improve_Amt')\n",
    "\n",
    "#File - rcd_inc1\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_inc1 = pd.read_csv(srcDir + 'rcd_inc1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_inc1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_inc2 \n",
    "pivFields = ['iss_per1000','sts_per1000','lts_per1000',\n",
    "             'exp_per1000','act_per1000','bha_per1000',\n",
    "             'rpt_per1000','arr_per1000']\n",
    "rcd_inc2 = PivotCsv(srcDir, 'rcd_inc2.csv',pivFields,'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_licenses  - Missing in 2019\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "#rcd_licenses = pd.read_csv(srcDir + 'rcd_licenses.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_licenses.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_location\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_location = pd.read_csv(srcDir + 'rcd_location.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_location.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Pivot File - rcd_naep !!!NATIONAL & STATE LEVEL DATA!!! - Missing in 2019\n",
    "#pivCols = ['grade','naep_subject','subgroup','Proficiency_level']\n",
    "#rcd_naep = PivotCsv(srcDir, 'rcd_naep.csv',['percent_proficient'],'agency_code', pivCols,'_NAEP')\n",
    "\n",
    "#File - rcd_nbpts - Missing in 2019\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "#rcd_nbpts = pd.read_csv(srcDir + 'rcd_nbpts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_nbpts.drop(['year','category_code','total_nbpts_num'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_pk_enroll - Missing in 2019\n",
    "#rcd_pk_enroll = PivotCsv(srcDir, 'rcd_pk_enroll.csv',['pct'],'agency_code', ['subgroup'],'_PK_ENROLL')\n",
    "\n",
    "#Pivot File - rcd_prin_demo - !!! District Level Data !!!\n",
    "rcd_prin_demo = PivotCsv(srcDir, 'rcd_prin_demo.csv',['pct_prin_demo'],'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_readiness\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_readiness = pd.read_csv(srcDir + 'rcd_readiness.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_readiness.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_sar - Missing in 2019\n",
    "#rcd_sar = PivotCsv(srcDir, 'rcd_sar.csv',['avg_size'],'agency_code', ['grade_eoc'],'_SAR')\n",
    "\n",
    "#File - rcd_sat\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_sat = pd.read_csv(srcDir + 'rcd_sat.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_sat.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_welcome\n",
    "rcd_welcome = pd.read_csv(srcDir + 'rcd_welcome.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_welcome.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#############  New files added for 2019 data #############\n",
    "# rcd_ap_crs_list.csv and rcd_ap_crs_list.csv are look up files and excluded from processing\n",
    "\n",
    "#File - rcd_acc_eg\n",
    "rcd_acc_eg = PivotCsv(srcDir, 'rcd_acc_eg.csv',['eg_index','eg_score'],'agency_code', ['subject','subgroup'],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and display a list of all .csv file names for 2019 download\n",
    "rcdFiles = glob.glob(srcDir  + 'rcd*.csv')\n",
    "\n",
    "rcdFileNames = [ntpath.basename(x)[:-4] for x in rcdFiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save All Flattened Files to \\\\Raw Datasets Directory\n",
    "**This code saves all the flattened file versions as .csv files in \\\\Raw Datasets\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "rcd_acc_aapart, 57\n",
      "rcd_acc_act, 743\n",
      "rcd_acc_awa, 699\n",
      "rcd_acc_cgr, 743\n",
      "rcd_acc_eds, 2770\n",
      "rcd_acc_eg, 2548\n",
      "rcd_acc_elp, 1887\n",
      "rcd_acc_essa_desig, 2654\n",
      "rcd_acc_gp, 596\n",
      "rcd_acc_irm, 1279\n",
      "rcd_acc_lowperf, 2769\n",
      "rcd_acc_ltg, 2526\n",
      "rcd_acc_ltg_detail, 2666\n",
      "rcd_acc_mcr, 726\n",
      "rcd_acc_part, 2538\n",
      "rcd_acc_part_detail, 2538\n",
      "rcd_acc_rta, 1578\n",
      "rcd_acc_spg1, 2584\n",
      "rcd_acc_spg2, 2544\n",
      "rcd_acc_wk, 520\n",
      "rcd_ap, 578\n",
      "rcd_charter, 270\n",
      "rcd_courses2, 595\n",
      "rcd_cte_concentrators, 553\n",
      "rcd_cte_credentials, 533\n",
      "rcd_cte_endorsement, 529\n",
      "rcd_cte_enrollment, 1189\n",
      "rcd_dlmi, 2818\n",
      "rcd_ib, 51\n",
      "rcd_inc1, 3097\n",
      "rcd_inc2, 2719\n",
      "rcd_location, 2770\n",
      "rcd_prin_demo, 116\n",
      "rcd_readiness, 1308\n",
      "rcd_sat, 694\n",
      "rcd_welcome, 1222\n"
     ]
    }
   ],
   "source": [
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "for fileName in rcdFileNames:\n",
    "    eval(fileName).to_csv(dataDir + 'Flattened Datasets/' + fileName + '.csv', sep=',', index=False)\n",
    "    print(fileName + ', ' + str(len(eval(fileName).index)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original Statistical Profiles Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url='http://apps.schools.nc.gov/ords/f?p=145:221::CSV::::'\n",
    "statProfPath = dataDir + 'SRC_Datasets/' + 'ec_pupils.csv'\n",
    "\n",
    "#Passing this URL directly into pd.read_csv() threw HTTP errors - This is my workaround\n",
    "s = requests.get(url).content\n",
    "ec_pupils = pd.read_csv(io.StringIO(s.decode('utf-8')), low_memory=False\n",
    "                        , dtype={'LEA': object,'School': object})\n",
    "\n",
    "#Rename year for consistency\n",
    "ec_pupils.rename({'Year':'year'}, axis=1, inplace=True)\n",
    "\n",
    "#Create agency_code from LEA and School code as an index\n",
    "ec_pupils['agency_code'] = ec_pupils['LEA'] + ec_pupils['School']\n",
    "\n",
    "#Filter to 2018 school year (There is already 2019 school year data in this file)\n",
    "#ec_pupils = ec_pupils[ec_pupils.year == schoolYear]\n",
    "\n",
    "#Some schools are missing race data.  Get the most recent year of data available for each agency code\n",
    "ec_pupils = ec_pupils.sort_values(by=['agency_code', 'year'])\n",
    "ec_pupils = ec_pupils.drop_duplicates(subset=[\"agency_code\"], keep=\"last\")\n",
    "\n",
    "#Save the original data to the source datasets folder \n",
    "ec_pupils.to_csv(statProfPath, sep=',', index=False)\n",
    "\n",
    "#Get data for the most recent school year\n",
    "#CleanUpRcdFiles(statProfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flattened Statistical Profiles with Racial Composition Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "ec_pupils_pct, 2569\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "# Statistical Profiles - Student Body Racial Compositions at the School Level Reshape\n",
    "#\n",
    "# Statistical Profiles data are already one record per public school but must be converted to percentages\n",
    "# Creates a new dataset - ec_pupils_pct.csv\n",
    "#\n",
    "#***********************************************************************\n",
    "\n",
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "ec_pupils = pd.read_csv(statProfPath, low_memory=False, dtype={'agency_code': object})\n",
    "\n",
    "#Create Racial Composition summary variables\n",
    "ec_pupils['Indian'] = ec_pupils['Indian Male'] + ec_pupils['Indian Female']\n",
    "ec_pupils['Asian'] = ec_pupils['Asian Male'] + ec_pupils['Asian Female']\n",
    "ec_pupils['Hispanic'] = ec_pupils['Hispanic Male'] + ec_pupils['Hispanic Female']\n",
    "ec_pupils['Black'] = ec_pupils['Black Male'] + ec_pupils['Black Female']\n",
    "ec_pupils['White'] = ec_pupils['White Male'] + ec_pupils['White Female']\n",
    "ec_pupils['Pacific Island'] = ec_pupils['Pacific Island Male'] + ec_pupils['Pacific Island Female']\n",
    "ec_pupils['Two or  More'] = ec_pupils['Two or  More Male'] + ec_pupils['Two or  More Female']\n",
    "\n",
    "#The original total field is corrupted with non-printable characters and will not convert to int or float \n",
    "ec_pupils.drop(['Total'], axis=1, inplace=True)\n",
    "#Create a new totals field by summing race composition fields\n",
    "ec_pupils['Total'] = ec_pupils['Indian'] + ec_pupils['Asian'] + \\\n",
    "                     ec_pupils['Hispanic'] + ec_pupils['Black'] + \\\n",
    "                     ec_pupils['White'] + ec_pupils['Pacific Island'] + ec_pupils['Two or  More']\n",
    "#Convert Totals to float64 for division later\n",
    "ec_pupils['Total'] = ec_pupils['Total'].astype(np.float64)\n",
    "\n",
    "#Create Minority summary variables \n",
    "ec_pupils['Minority Male'] = ec_pupils['Indian Male'] + ec_pupils['Asian Male'] \\\n",
    "                           + ec_pupils['Hispanic Male'] + ec_pupils['Black Male'] \\\n",
    "                           + ec_pupils['Pacific Island Male'] + ec_pupils['Two or  More Male'] \n",
    "ec_pupils['Minority Female'] = ec_pupils['Indian Female'] + ec_pupils['Asian Female'] \\\n",
    "                           + ec_pupils['Hispanic Female'] + ec_pupils['Black Female'] \\\n",
    "                           + ec_pupils['Pacific Island Female'] + ec_pupils['Two or  More Female']\n",
    "ec_pupils['Minority'] = ec_pupils['Minority Male'] + ec_pupils['Minority Female']\n",
    "\n",
    "#Create Student Body Racial Composition PERCENTAGES at the School Level\n",
    "ec_pupils_pct = pd.DataFrame({'agency_code'   : ec_pupils['agency_code']\n",
    "                            , 'School Name' : ec_pupils['___School Name___']\n",
    "                            , 'IndianPct'   : ec_pupils['Indian'] / ec_pupils['Total']  \n",
    "                            , 'AsianPct'    : ec_pupils['Asian'] / ec_pupils['Total']\n",
    "                            , 'HispanicPct' : ec_pupils['Hispanic'] / ec_pupils['Total']\n",
    "                            , 'BlackPct'    : ec_pupils['Black'] / ec_pupils['Total']\n",
    "                            , 'WhitePct'    : ec_pupils['White'] / ec_pupils['Total']\n",
    "                            , 'PacificIslandPct': ec_pupils['Pacific Island'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMorePct': ec_pupils['Two or  More'] / ec_pupils['Total']\n",
    "                            , 'MinorityPct' : ec_pupils['Minority'] / ec_pupils['Total']\n",
    "                            \n",
    "                              \n",
    "                            , 'IndianMalePct'   : ec_pupils['Indian Male'] / ec_pupils['Total']  \n",
    "                            , 'AsianMalePct'    : ec_pupils['Asian Male'] / ec_pupils['Total']\n",
    "                            , 'HispanicMalePct' : ec_pupils['Hispanic Male'] / ec_pupils['Total']\n",
    "                            , 'BlackMalePct'    : ec_pupils['Black Male'] / ec_pupils['Total']\n",
    "                            , 'WhiteMalePct'    : ec_pupils['White Male'] / ec_pupils['Total']\n",
    "                            , 'PacificIslandMalePct': ec_pupils['Pacific Island Male'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMoreMalePct': ec_pupils['Two or  More Male'] / ec_pupils['Total']  \n",
    "                            , 'MinorityMalePct' : ec_pupils['Minority Male'] / ec_pupils['Total']\n",
    "                                                          \n",
    "                            , 'IndianFemalePct'   : ec_pupils['Indian Female'] / ec_pupils['Total']  \n",
    "                            , 'AsianFemalePct'    : ec_pupils['Asian Female'] / ec_pupils['Total']\n",
    "                            , 'HispanicFemalePct' : ec_pupils['Hispanic Female'] / ec_pupils['Total']\n",
    "                            , 'BlackFemalePct'    : ec_pupils['Black Female'] / ec_pupils['Total']\n",
    "                            , 'WhiteFemalePct'    : ec_pupils['White Female'] / ec_pupils['Total']\n",
    "                            , 'MinorityFemalePct' : ec_pupils['Minority Female'] / ec_pupils['Total'] \n",
    "                            , 'PacificIslandFemalePct': ec_pupils['Pacific Island Female'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMoreFemalePct': ec_pupils['Two or  More Female'] / ec_pupils['Total']\n",
    "                             })\n",
    "\n",
    "#Save the flattened racial composition percentage data to disk \n",
    "ec_pupils_pct.to_csv(dataDir + 'Flattened Datasets/' + 'ec_pupils_pct.csv', sep=',', index=False)\n",
    "\n",
    "#Print file details\n",
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "print('ec_pupils_pct' + ', ' + str(len(ec_pupils_pct.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rcd_pk_enroll.csv Counts Flattened File\n",
    "* The rcd_pk_enroll.csv percentages always = 1 for the _ALL subgroup (only shows distribution of race)\n",
    "* Adding actual PK enrollment counts to track PK enrollment growth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot File - rcd_pk_enroll - Missing in 2019\n",
    "#rcd_pk_enroll_ct = PivotCsv(dataDir, 'SRC_Datasets/rcd_pk_enroll.csv',['count'],'agency_code', ['subgroup'],'_PK_ENROLL')\n",
    "\n",
    "#rcd_pk_enroll_ct.to_csv(dataDir + 'Flattened Datasets/' + 'rcd_pk_enroll_ct.csv', sep=',', index=False)\n",
    "#print('rcd_pk_enroll_ct' + ', ' + str(rcd_pk_enroll_ct.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
