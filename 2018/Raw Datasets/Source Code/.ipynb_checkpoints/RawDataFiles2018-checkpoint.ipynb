{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NCDPI 2017-2018 Raw Datasets\n",
    "### This program downloads all original datasets from www.ncpublicschools.org and saves them as .csv files. These data files are used to create all the flattened and machine learning datasets within the NCEA repository.\n",
    "\n",
    "1. This notebook downloads raw datasets directly from NCDPI specific URLs.\n",
    "2. Each raw dataset is filtered by school year and saved in the original layout as a .csv file.\n",
    "3. For consistency, both the Year and School code fields are renamed to \"year\" and \"unit_code\" in all files.\n",
    "4. All masking is removed from raw data fields using the following code: replace({\"*\":0, \">95\":100, \"<5\":0, \"<10\":5 })\n",
    "5. All * or carriage returns are removed from column names.\n",
    "6. Duplicate column names in accDrillDown files are renamed to include _Ct at the end for all count fields.\n",
    "7. All raw datasets created by this program are used to create the \"flattened\" and \"machine learning\" Public School datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to add the correct packages path to your jupyter enviroment, if it is missing. \n",
    "#import sys\n",
    "#sys.path.append('C:/Users/Jake/Anaconda2/envs/example_env/Lib/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#**********************************************************************************\n",
    "# Set the following variables before running this code!!!\n",
    "#**********************************************************************************\n",
    "\n",
    "#Location where copies of the raw data files will be downloaded and saved as csv files.\n",
    "#'C:/Users/Jake/Documents/GitHub/EducationDataNC/2018/Raw Datasets/'\n",
    "dataDir = 'D:/BenepactLLC/Belk/NC_Report_Card_Data/2019/April 2019/2018/Raw Datasets/'\n",
    "\n",
    "#All raw data files are filtered for the year below\n",
    "schoolYear = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "#Download and save an original copy of the raw data \n",
    "url=\"http://www.ncpublicschools.org/docs/src/researchers/src-datasets.zip\"\n",
    "zipFilePath = dataDir + 'src-datasets.zip'\n",
    "urllib.request.urlretrieve(url, zipFilePath)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#Extract the zip file and all school datasets to the //Raw Datasets/ folder\n",
    "zip_ref = zipfile.ZipFile(zipFilePath, 'r')\n",
    "zip_ref.extractall(dataDir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Most Recent Year of Data from Each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use ntpath.basename to get a filename from a filepath\n",
    "import ntpath\n",
    "\n",
    "def CleanUpRcdFiles(filePath):\n",
    "    fileName = ntpath.basename(filePath)\n",
    "    schFile = pd.read_csv(filePath, dtype={'agency_code': object}, low_memory=False)\n",
    "    maxYear = schFile['year'].max()\n",
    "    \n",
    "    #Filter records for the most recent year\n",
    "    schFile = schFile[schFile['year'] == maxYear]\n",
    "    \n",
    "    #Remove state and district level summary records \n",
    "    #schFile = schFile[(schFile['agency_code'] != 'NC-SEA') & (schFile['agency_code'].str.contains(\"LEA\") == False)]\n",
    "        \n",
    "    #Remove * character from any fields. \n",
    "    schFile = schFile.replace({'*':''})\n",
    "    schFile.to_csv(dataDir + fileName, sep=',', index=False)\n",
    "    \n",
    "    print(fileName + ', Max Year: ' + str(maxYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Files to: D:/BenepactLLC/Belk/NC_Report_Card_Data/2019/April 2019/2018/Raw Datasets/\n",
      "\n",
      "rcd_161.csv, Max Year: 2012\n",
      "rcd_acc_aapart.csv, Max Year: 2018\n",
      "rcd_acc_act.csv, Max Year: 2018\n",
      "rcd_acc_awa.csv, Max Year: 2018\n",
      "rcd_acc_cgr.csv, Max Year: 2018\n",
      "rcd_acc_eds.csv, Max Year: 2018\n",
      "rcd_acc_elp.csv, Max Year: 2018\n",
      "rcd_acc_essa_desig.csv, Max Year: 2018\n",
      "rcd_acc_gp.csv, Max Year: 2018\n",
      "rcd_acc_irm.csv, Max Year: 2018\n",
      "rcd_acc_lowperf.csv, Max Year: 2018\n",
      "rcd_acc_ltg.csv, Max Year: 2018\n",
      "rcd_acc_ltg_detail.csv, Max Year: 2018\n",
      "rcd_acc_mcr.csv, Max Year: 2018\n",
      "rcd_acc_part.csv, Max Year: 2018\n",
      "rcd_acc_part_detail.csv, Max Year: 2018\n",
      "rcd_acc_pc.csv, Max Year: 2018\n",
      "rcd_acc_rta.csv, Max Year: 2018\n",
      "rcd_acc_spg1.csv, Max Year: 2017\n",
      "rcd_acc_spg2.csv, Max Year: 2018\n",
      "rcd_acc_wk.csv, Max Year: 2018\n",
      "rcd_adm.csv, Max Year: 2018\n",
      "rcd_ap.csv, Max Year: 2018\n",
      "rcd_arts.csv, Max Year: 2018\n",
      "rcd_att.csv, Max Year: 2018\n",
      "rcd_charter.csv, Max Year: 2018\n",
      "rcd_chronic_absent.csv, Max Year: 2018.0\n",
      "rcd_college.csv, Max Year: 2017\n",
      "rcd_courses1.csv, Max Year: 2017\n",
      "rcd_courses2.csv, Max Year: 2018\n",
      "rcd_cte_concentrators.csv, Max Year: 2018\n",
      "rcd_cte_credentials.csv, Max Year: 2018\n",
      "rcd_cte_endorsement.csv, Max Year: 2018\n",
      "rcd_cte_enrollment.csv, Max Year: 2018\n",
      "rcd_dlmi.csv, Max Year: 2018\n",
      "rcd_effectiveness.csv, Max Year: 2017\n",
      "rcd_esea_att.csv, Max Year: 2015\n",
      "rcd_experience.csv, Max Year: 2018\n",
      "rcd_funds.csv, Max Year: 2018\n",
      "rcd_hqt.csv, Max Year: 2016\n",
      "rcd_ib.csv, Max Year: 2018\n",
      "rcd_improvement.csv, Max Year: 2018\n",
      "rcd_inc1.csv, Max Year: 2017\n",
      "rcd_inc2.csv, Max Year: 2018\n",
      "rcd_licenses.csv, Max Year: 2018\n",
      "rcd_location.csv, Max Year: 2018\n",
      "rcd_naep.csv, Max Year: 2017\n",
      "rcd_nbpts.csv, Max Year: 2018\n",
      "rcd_pk_enroll.csv, Max Year: 2018\n",
      "rcd_prin_demo.csv, Max Year: 2018\n",
      "rcd_readiness.csv, Max Year: 2018\n",
      "rcd_sar.csv, Max Year: 2018\n",
      "rcd_sat.csv, Max Year: 2018\n",
      "rcd_welcome.csv, Max Year: 2018\n"
     ]
    }
   ],
   "source": [
    "#Use wildcards to find files in a directory\n",
    "import glob\n",
    "\n",
    "#Get and display a list of all .csv file names for 2018 download\n",
    "rcdFiles = glob.glob(dataDir + 'SRC_Datasets/' + 'rcd*.csv')\n",
    "\n",
    "print('Saving Files to: ' + dataDir + '\\n')\n",
    "\n",
    "for filePth in rcdFiles:\n",
    "    fileName = ntpath.basename(filePth)\n",
    "    if fileName != 'rcd_code_desc.csv': \n",
    "        CleanUpRcdFiles(filePth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove comma from amount field in rcd_improvement\n",
    "rcd_improvement = pd.read_csv(dataDir + 'rcd_improvement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_improvement['amount'] = rcd_improvement['amount'].str.replace(',', '').astype(float)\n",
    "rcd_improvement.to_csv(dataDir + 'rcd_improvement.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the Raw Data Files\n",
    "### This section reads raw data files directly from the \\\\Raw Datasets folder and flattens each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A List of All Files Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and display a list of all .csv file names for 2018 download\n",
    "rcdFiles = glob.glob(dataDir + 'rcd*.csv')\n",
    "\n",
    "rcdFileNames = [ntpath.basename(x)[:-4] for x in rcdFiles]\n",
    "\n",
    "#print('A List of File Names and Record Counts for Processing:\\n')\n",
    "\n",
    "#for fileName in rcdFileNames:\n",
    "#    print(fileName + ', ' + str(len(eval(fileName).index)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten All Files \n",
    "**This section uses table pivots and other cleanup to reduce each file to 1 record per agency code.**\n",
    "1. Each agency_code could represent National, State, District, Or School Campus level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PivotCsv(dataDir, fileName, pivValues, pivIndex, pivColumns, colSuffix):\n",
    "    pivFile = pd.read_csv(dataDir + fileName, low_memory=False, dtype={pivIndex: object})\n",
    "    \n",
    "    pivFile[pivColumns] = pivFile[pivColumns].astype(object)\n",
    "    \n",
    "    pivFile = pd.pivot_table(pivFile, values=pivValues,index=pivIndex,columns=pivColumns)\n",
    "    \n",
    "    #concatenate multiindex column names using a list comprehension.\n",
    "    if len(pivColumns) >= 2:\n",
    "        pivFile.columns = [ '_'.join(str(i) for i in col)  + '' for col in pivFile.columns]\n",
    "        #pivFile.columns = ['_'.join(col) + colSuffix for col in pivFile.columns]\n",
    "    else:\n",
    "        pivFile.columns = [str(col) + colSuffix for col in pivFile.columns]\n",
    "    \n",
    "    #Make our index a column for merges later\n",
    "    pivFile.reset_index(level=0, inplace=True)\n",
    "    return pivFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot File - rcd_161 \n",
    "rcd_161 = PivotCsv(dataDir, 'rcd_161.csv','ccc_pct','agency_code', ['status','subgroup'],'_CCC_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_aapart \n",
    "rcd_acc_aapart = PivotCsv(dataDir, 'rcd_acc_aapart.csv','pct','agency_code', ['subject','grade'],'_AAPART_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_act \n",
    "rcd_acc_act = PivotCsv(dataDir, 'rcd_acc_act.csv','pct','agency_code', ['subject','subgroup'],'_ACT_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_awa \n",
    "rcd_acc_awa = PivotCsv(dataDir, 'rcd_acc_awa.csv','pct','agency_code', ['subgroup'],'_AWA_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_cgr\n",
    "rcd_acc_cgr = PivotCsv(dataDir, 'rcd_acc_cgr.csv','pct','agency_code', ['cgr_type', 'subgroup'],'_CGR_PCT')\n",
    "\n",
    "#File - rcd_acc_eds\n",
    "rcd_acc_eds = pd.read_csv(dataDir + 'rcd_acc_eds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_eds = rcd_acc_eds[['agency_code', 'pct_eds']]\n",
    "\n",
    "#Pivot File - rcd_acc_elp\n",
    "rcd_acc_elp = PivotCsv(dataDir, 'rcd_acc_elp.csv','pct','agency_code', ['subgroup'],'_ELP_PCT')\n",
    "\n",
    "#File - rcd_acc_essa_desig\n",
    "rcd_acc_essa_desig = pd.read_csv(dataDir + 'rcd_acc_essa_desig.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_essa_desig.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_gp\n",
    "rcd_acc_gp = pd.read_csv(dataDir + 'rcd_acc_gp.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_gp.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_irm\n",
    "rcd_acc_irm = PivotCsv(dataDir, 'rcd_acc_irm.csv','pct_prof','agency_code', ['grade'],'gr_irm_pct_prof')\n",
    "\n",
    "#File - rcd_acc_lowperf\n",
    "rcd_acc_lowperf = pd.read_csv(dataDir + 'rcd_acc_lowperf.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_lowperf = rcd_acc_lowperf[['agency_code', 'lp_school','rlp_school','clpc_school']]\n",
    "\n",
    "#Pivot File - rcd_acc_ltg\n",
    "rcd_acc_ltg = PivotCsv(dataDir, 'rcd_acc_ltg.csv','pct_met','agency_code', ['target'],'_LTG_PCT_MET')\n",
    "\n",
    "#File - rcd_acc_ltg_detail\n",
    "rcd_acc_ltg_detail = pd.read_csv(dataDir + 'rcd_acc_ltg_detail.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_ltg_detail.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_mcr\n",
    "rcd_acc_mcr = PivotCsv(dataDir, 'rcd_acc_mcr.csv','pct','agency_code', ['subgroup'],'_MCR_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_part = PivotCsv(dataDir, 'rcd_acc_part.csv','pct_met','agency_code', ['target'],'_PART_PCT_MET')\n",
    "\n",
    "#Pivot File - rcd_acc_part\n",
    "rcd_acc_part_detail = PivotCsv(dataDir, 'rcd_acc_part_detail.csv','pct','agency_code', ['target','subgroup'],'_PART_DET_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_pc - WARNING 3323 columns!!! \n",
    "rcd_acc_pc = PivotCsv(dataDir, 'rcd_acc_pc.csv','pct','agency_code', ['standard','subject','grade','subgroup'],'_PC_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_rta = PivotCsv(dataDir, 'rcd_acc_rta.csv','pct','agency_code', ['metric'],'_RTA_PCT')\n",
    "\n",
    "#File - rcd_acc_spg1\n",
    "rcd_acc_spg1 = pd.read_csv(dataDir + 'rcd_acc_spg1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_spg1.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_spg2\n",
    "pivVals = ['aaa_score','awa_score','cgrs_score','elp_score','mcr_score','scgs_score','bi_score',\n",
    "           'ach_score','eg_status','eg_score','spg_score','spg_grade']\n",
    "           \n",
    "rcd_acc_spg2 = PivotCsv(dataDir, 'rcd_acc_spg2.csv',pivVals,'agency_code', ['subgroup'],'_MCR_PCT')\n",
    "\n",
    "#Pivot File - rcd_acc_wk\n",
    "rcd_acc_wk = PivotCsv(dataDir, 'rcd_acc_wk.csv','pct','agency_code', ['subgroup'],'_WK_PCT')\n",
    "\n",
    "#File - rcd_adm\n",
    "rcd_adm = pd.read_csv(dataDir + 'rcd_adm.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_adm.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_ap\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_ap = pd.read_csv(dataDir + 'rcd_ap.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ap.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_arts\n",
    "rcd_arts = pd.read_csv(dataDir + 'rcd_arts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_arts.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_att\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_att = pd.read_csv(dataDir + 'rcd_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_charter\n",
    "rcd_charter = PivotCsv(dataDir, 'rcd_charter.csv','pct_enrolled','agency_code', ['home_lea','subgroup'],'_CHARTER_PCT')\n",
    "\n",
    "#Pivot File - rcd_chronic_absent\n",
    "rcd_chronic_absent = PivotCsv(dataDir, 'rcd_chronic_absent.csv','pct','agency_code', ['subgroup'],'_CHRON_ABSENT_PCT')\n",
    "\n",
    "#Pivot File - rcd_college\n",
    "rcd_college = PivotCsv(dataDir, 'rcd_college.csv','pct_enrolled','agency_code', ['status','subgroup'],'_COLLEGE_PCT')\n",
    "\n",
    "#File - rcd_courses1 - 2017 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_courses1 = pd.read_csv(dataDir + 'rcd_courses1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_courses1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_courses2\n",
    "rcd_courses2 = PivotCsv(dataDir, 'rcd_courses2.csv',['pct_ap','pct_ccp','pct_ib'],'agency_code', ['category_code','subgroup'],'_COURSES2')\n",
    "\n",
    "#Pivot File - rcd_cte_concentrators\n",
    "rcd_cte_concentrators = PivotCsv(dataDir, 'rcd_cte_concentrators.csv','num_concentrators','agency_code', ['career_cluster'],'_CTE_CONCENTRATORS')\n",
    "\n",
    "#File - rcd_cte_credentials\n",
    "rcd_cte_credentials = pd.read_csv(dataDir + 'rcd_cte_credentials.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_credentials.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_endorsement\n",
    "rcd_cte_endorsement = pd.read_csv(dataDir + 'rcd_cte_endorsement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_endorsement.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_enrollment\n",
    "rcd_cte_enrollment = pd.read_csv(dataDir + 'rcd_cte_enrollment.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_enrollment['cte_enrollment_pct'] = rcd_cte_enrollment['pct'] \n",
    "rcd_cte_enrollment.drop(['year','pct'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_dlmi\n",
    "rcd_dlmi = pd.read_csv(dataDir + 'rcd_dlmi.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_dlmi.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_effectiveness - 2017 Data\n",
    "rcd_effectiveness = PivotCsv(dataDir, 'rcd_effectiveness.csv',['pct_rating'],'agency_code', ['ee_standard','ee_rating'],'')\n",
    "\n",
    "#File - rcd_esea_att - 2015 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_esea_att = pd.read_csv(dataDir + 'rcd_esea_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_esea_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_experience\n",
    "expPivColumns = ['pct_experience_0','pct_experience_10','pct_experience_4',\n",
    "                 'pct_adv_degree','pct_turnover','total_class_teach','avg_class_teach']\n",
    "rcd_experience = PivotCsv(dataDir, 'rcd_experience.csv',expPivColumns,'agency_code', 'staff','Exp')\n",
    "\n",
    "#File - !!!DISTRICT LEVEL DATA!!!\n",
    "rcd_funds = pd.read_csv(dataDir + 'rcd_funds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_funds.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_hqt - 2016 DATA\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_hqt = pd.read_csv(dataDir + 'rcd_hqt.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_hqt.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_ib\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_ib = pd.read_csv(dataDir + 'rcd_ib.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ib.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_improvement\n",
    "rcd_improvement = PivotCsv(dataDir, 'rcd_improvement.csv','amount','agency_code', ['strategy'],'_Improve_Amt')\n",
    "\n",
    "#File - rcd_inc1\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_inc1 = pd.read_csv(dataDir + 'rcd_inc1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_inc1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_inc2 \n",
    "pivFields = ['iss_per1000','sts_per1000','lts_per1000',\n",
    "             'exp_per1000','crime_per1000','blhr_per1000',\n",
    "             'rplw_per1000','arre_per1000']\n",
    "rcd_inc2 = PivotCsv(dataDir, 'rcd_inc2.csv',pivFields,'agency_code', 'subgroup','')\n",
    "\n",
    "#File - rcd_licenses\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_licenses = pd.read_csv(dataDir + 'rcd_licenses.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_licenses.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_location\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_location = pd.read_csv(dataDir + 'rcd_location.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_location.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Pivot File - rcd_naep !!!NATIONAL & STATE LEVEL DATA!!!\n",
    "pivCols = ['grade','naep_subject','subgroup','Proficiency_level']\n",
    "rcd_naep = PivotCsv(dataDir, 'rcd_naep.csv','percent_proficient','agency_code', pivCols,'')\n",
    "\n",
    "#File - rcd_licenses\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_nbpts = pd.read_csv(dataDir + 'rcd_nbpts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_nbpts.drop(['year','category_code','total_nbpts_num'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_pk_enroll\n",
    "rcd_pk_enroll = PivotCsv(dataDir, 'rcd_pk_enroll.csv','pct','agency_code', ['subgroup'],'_PK_ENROLL_PCT')\n",
    "\n",
    "#Pivot File - rcd_prin_demo - !!! District Level Data !!!\n",
    "rcd_prin_demo = PivotCsv(dataDir, 'rcd_prin_demo.csv','pct_prin_demo','agency_code', ['subgroup'],'_PCT_PRIN_DEMO')\n",
    "\n",
    "#File - rcd_readiness\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_readiness = pd.read_csv(dataDir + 'rcd_readiness.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_readiness.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_sar\n",
    "rcd_sar = PivotCsv(dataDir, 'rcd_sar.csv','avg_size','agency_code', ['grade_eoc'],'_SAR_AVG_SIZE')\n",
    "\n",
    "#File - rcd_sat\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_sat = pd.read_csv(dataDir + 'rcd_sat.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_sat.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_welcome\n",
    "rcd_welcome = pd.read_csv(dataDir + 'rcd_welcome.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_welcome.drop(['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save All Flattened Files to \\\\Raw Datasets Directory\n",
    "**This code saves all the flattened file versions as .csv files in \\\\Raw Datasets\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "rcd_161, 644\n",
      "rcd_acc_aapart, 53\n",
      "rcd_acc_act, 742\n",
      "rcd_acc_awa, 688\n",
      "rcd_acc_cgr, 738\n",
      "rcd_acc_eds, 2761\n",
      "rcd_acc_elp, 1809\n",
      "rcd_acc_essa_desig, 2645\n",
      "rcd_acc_gp, 658\n",
      "rcd_acc_irm, 1276\n",
      "rcd_acc_lowperf, 2760\n",
      "rcd_acc_ltg, 2461\n",
      "rcd_acc_ltg_detail, 2631\n",
      "rcd_acc_mcr, 717\n",
      "rcd_acc_part, 2527\n",
      "rcd_acc_part_detail, 2527\n",
      "rcd_acc_pc, 2697\n",
      "rcd_acc_rta, 1576\n",
      "rcd_acc_spg1, 2584\n",
      "rcd_acc_spg2, 2538\n",
      "rcd_acc_wk, 517\n",
      "rcd_adm, 3197\n",
      "rcd_ap, 563\n",
      "rcd_arts, 2509\n",
      "rcd_att, 3115\n",
      "rcd_charter, 241\n",
      "rcd_chronic_absent, 2719\n",
      "rcd_college, 690\n",
      "rcd_courses1, 773\n",
      "rcd_courses2, 636\n",
      "rcd_cte_concentrators, 492\n",
      "rcd_cte_credentials, 436\n",
      "rcd_cte_endorsement, 537\n",
      "rcd_cte_enrollment, 1184\n",
      "rcd_dlmi, 2723\n",
      "rcd_effectiveness, 2724\n",
      "rcd_esea_att, 2700\n",
      "rcd_experience, 2758\n",
      "rcd_funds, 292\n",
      "rcd_hqt, 3073\n",
      "rcd_ib, 51\n",
      "rcd_improvement, 19\n",
      "rcd_inc1, 3097\n",
      "rcd_inc2, 2792\n",
      "rcd_licenses, 3121\n",
      "rcd_location, 2759\n",
      "rcd_naep, 2\n",
      "rcd_nbpts, 3124\n",
      "rcd_pk_enroll, 988\n",
      "rcd_prin_demo, 116\n",
      "rcd_readiness, 1323\n",
      "rcd_sar, 2630\n",
      "rcd_sat, 613\n",
      "rcd_welcome, 1311\n"
     ]
    }
   ],
   "source": [
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "for fileName in rcdFileNames:\n",
    "    eval(fileName).to_csv(dataDir + fileName + '.csv', sep=',', index=False)\n",
    "    print(fileName + ', ' + str(len(eval(fileName).index)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
