{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NCDPI 2017-2018 Raw Datasets\n",
    "### This program downloads all original datasets from www.ncpublicschools.org and saves them as .csv files. These data files are used to create all the flattened and machine learning datasets within the NCEA repository.\n",
    "\n",
    "1. This notebook downloads raw datasets directly from NCDPI specific URLs.\n",
    "2. Each raw dataset is filtered by school year and saved in the original layout as a .csv file.\n",
    "3. For consistency, both the Year and School code fields are renamed to \"year\" and \"agency_code\" in all files.\n",
    "4. All masking is removed from raw data fields using the following code: replace({\"*\":0, \">95\":100, \"<5\":0, \"<10\":5 })\n",
    "5. All * or carriage returns are removed from column names.\n",
    "6. All raw datasets created by this program are used to create the \"flattened\" and \"machine learning\" Public School datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to add the correct packages path to your jupyter enviroment, if it is missing. \n",
    "#import sys\n",
    "#sys.path.append('C:/Users/Jake/Anaconda2/envs/example_env/Lib/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#**********************************************************************************\n",
    "# Set the following variables before running this code!!!\n",
    "#**********************************************************************************\n",
    "\n",
    "#Location where copies of the raw data files will be downloaded and saved as csv files.\n",
    "dataDir = 'D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2018/Raw Datasets/'\n",
    "\n",
    "#All raw data files are filtered for the year below\n",
    "schoolYear = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original SRC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "#Download and save an original copy of the raw SRC data \n",
    "url=\"http://www.ncpublicschools.org/docs/src/researchers/src-datasets.zip\"\n",
    "zipFilePath = dataDir + 'src-datasets.zip'\n",
    "\n",
    "#Comment out the next line after downloading the original data one time! \n",
    "#urllib.request.urlretrieve(url, zipFilePath)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#Extract the zip file and all school datasets to the //Raw Datasets/ folder\n",
    "zip_ref = zipfile.ZipFile(zipFilePath, 'r')\n",
    "zip_ref.extractall(dataDir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Most Recent Year of Data from Each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataDir path for this part\n",
    "dataDir = dataDir + 'SRC_Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use ntpath.basename to get a filename from a filepath\n",
    "import ntpath\n",
    "\n",
    "def CleanUpRcdFiles(filePath):\n",
    "    fileName = ntpath.basename(filePath)\n",
    "    schFile = pd.read_csv(filePath, dtype={'agency_code': object}, low_memory=False)\n",
    "    maxYear = schFile['year'].max()\n",
    "    \n",
    "    #Filter records for the most recent year\n",
    "    schFile = schFile[schFile['year'] == maxYear]\n",
    "    \n",
    "    #Remove state and district level summary records \n",
    "    #schFile = schFile[(schFile['agency_code'] != 'NC-SEA') & (schFile['agency_code'].str.contains(\"LEA\") == False)]\n",
    "        \n",
    "    #Remove * character from any fields. \n",
    "    schFile = schFile.replace({'*':''})\n",
    "    schFile.to_csv(dataDir + fileName, sep=',', index=False)\n",
    "    \n",
    "    print(fileName + ', Max Year: ' + str(maxYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Files to: D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2018/Raw Datasets/SRC_Datasets/\n",
      "\n",
      "rcd_161.csv, Max Year: 2012\n",
      "rcd_acc_aapart.csv, Max Year: 2018\n",
      "rcd_acc_act.csv, Max Year: 2018\n",
      "rcd_acc_awa.csv, Max Year: 2018\n",
      "rcd_acc_cgr.csv, Max Year: 2018\n",
      "rcd_acc_eds.csv, Max Year: 2018\n",
      "rcd_acc_elp.csv, Max Year: 2018\n",
      "rcd_acc_essa_desig.csv, Max Year: 2018\n",
      "rcd_acc_gp.csv, Max Year: 2018\n",
      "rcd_acc_irm.csv, Max Year: 2018\n",
      "rcd_acc_lowperf.csv, Max Year: 2018\n",
      "rcd_acc_ltg.csv, Max Year: 2018\n",
      "rcd_acc_ltg_detail.csv, Max Year: 2018\n",
      "rcd_acc_mcr.csv, Max Year: 2018\n",
      "rcd_acc_part.csv, Max Year: 2018\n",
      "rcd_acc_part_detail.csv, Max Year: 2018\n",
      "rcd_acc_pc.csv, Max Year: 2018\n",
      "rcd_acc_rta.csv, Max Year: 2018\n",
      "rcd_acc_spg1.csv, Max Year: 2017\n",
      "rcd_acc_spg2.csv, Max Year: 2018\n",
      "rcd_acc_wk.csv, Max Year: 2018\n",
      "rcd_adm.csv, Max Year: 2018\n",
      "rcd_ap.csv, Max Year: 2018\n",
      "rcd_arts.csv, Max Year: 2018\n",
      "rcd_att.csv, Max Year: 2018\n",
      "rcd_charter.csv, Max Year: 2018\n",
      "rcd_chronic_absent.csv, Max Year: 2018.0\n",
      "rcd_college.csv, Max Year: 2017\n",
      "rcd_courses1.csv, Max Year: 2017\n",
      "rcd_courses2.csv, Max Year: 2018\n",
      "rcd_cte_concentrators.csv, Max Year: 2018\n",
      "rcd_cte_credentials.csv, Max Year: 2018\n",
      "rcd_cte_endorsement.csv, Max Year: 2018\n",
      "rcd_cte_enrollment.csv, Max Year: 2018\n",
      "rcd_dlmi.csv, Max Year: 2018\n",
      "rcd_effectiveness.csv, Max Year: 2017\n",
      "rcd_esea_att.csv, Max Year: 2015\n",
      "rcd_experience.csv, Max Year: 2018\n",
      "rcd_funds.csv, Max Year: 2018\n",
      "rcd_hqt.csv, Max Year: 2016\n",
      "rcd_ib.csv, Max Year: 2018\n",
      "rcd_improvement.csv, Max Year: 2018\n",
      "rcd_inc1.csv, Max Year: 2017\n",
      "rcd_inc2.csv, Max Year: 2018\n",
      "rcd_licenses.csv, Max Year: 2018\n",
      "rcd_location.csv, Max Year: 2018\n",
      "rcd_naep.csv, Max Year: 2017\n",
      "rcd_nbpts.csv, Max Year: 2018\n",
      "rcd_pk_enroll.csv, Max Year: 2018\n",
      "rcd_prin_demo.csv, Max Year: 2018\n",
      "rcd_readiness.csv, Max Year: 2018\n",
      "rcd_sar.csv, Max Year: 2018\n",
      "rcd_sat.csv, Max Year: 2018\n",
      "rcd_welcome.csv, Max Year: 2018\n"
     ]
    }
   ],
   "source": [
    "#Use wildcards to find files in a directory\n",
    "import glob\n",
    "\n",
    "#Get and display a list of all .csv file names for 2018 download\n",
    "rcdFiles = glob.glob(dataDir + 'rcd*.csv')\n",
    "\n",
    "print('Saving Files to: ' + dataDir + '\\n')\n",
    "\n",
    "for filePth in rcdFiles:\n",
    "    fileName = ntpath.basename(filePth)\n",
    "    if fileName != 'rcd_code_desc.csv': \n",
    "        CleanUpRcdFiles(filePth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove comma from amount field in rcd_improvement\n",
    "rcd_improvement = pd.read_csv(dataDir + 'rcd_improvement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_improvement['amount'] = rcd_improvement['amount'].astype(str).str.replace(',', '').astype(float)\n",
    "rcd_improvement.to_csv(dataDir + 'rcd_improvement.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the Raw Data Files\n",
    "### This section reads raw data files directly from the \\\\Raw Datasets folder and flattens each file.\n",
    "1. Each agency_code could represent National, State, District, Or School Campus level data.\n",
    "2. This code creates new data columns using pivots until there is only one record per agency_code.\n",
    "3. Percentage fields are always used for pivot values in cases where count, denominators, or percentages are available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and display a list of all .csv file names for 2018 download\n",
    "rcdFiles = glob.glob(dataDir + 'rcd*.csv')\n",
    "\n",
    "rcdFileNames = [ntpath.basename(x)[:-4] for x in rcdFiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not process the rcd_code_desc file  \n",
    "rcdFileNames.remove('rcd_code_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PivotCsv(dataDir, fileName, pivValues, pivIndex, pivColumns, colSuffix):\n",
    "    pivFile = pd.read_csv(dataDir + fileName, low_memory=False, dtype={pivIndex: object})\n",
    "    \n",
    "    pivFile = pd.pivot_table(pivFile, values=pivValues,index=pivIndex,columns=pivColumns)\n",
    "    \n",
    "    #concatenate multiindex column names using a list comprehension.\n",
    "    pivFile.columns = [ '_'.join(str(i) for i in col) + colSuffix for col in pivFile.columns]\n",
    "\n",
    "    #Make our index a column for merges later\n",
    "    pivFile.reset_index(level=0, inplace=True)\n",
    "    return pivFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot File - rcd_161 \n",
    "rcd_161 = PivotCsv(dataDir, 'rcd_161.csv',['ccc_pct'],'agency_code', ['status','subgroup'],'_161')\n",
    "\n",
    "#Pivot File - rcd_acc_aapart \n",
    "rcd_acc_aapart = PivotCsv(dataDir, 'rcd_acc_aapart.csv',['pct'],'agency_code', ['subject','grade'],'_AAPART')\n",
    "\n",
    "#Pivot File - rcd_acc_act \n",
    "rcd_acc_act = PivotCsv(dataDir, 'rcd_acc_act.csv',['pct'],'agency_code', ['subject','subgroup'],'_ACT')\n",
    "\n",
    "#Pivot File - rcd_acc_awa \n",
    "rcd_acc_awa = PivotCsv(dataDir, 'rcd_acc_awa.csv',['pct'],'agency_code', ['subgroup'],'_AWA')\n",
    "\n",
    "#Pivot File - rcd_acc_cgr\n",
    "rcd_acc_cgr = PivotCsv(dataDir, 'rcd_acc_cgr.csv',['pct'],'agency_code', ['cgr_type', 'subgroup'],'_CGR')\n",
    "\n",
    "#File - rcd_acc_eds\n",
    "rcd_acc_eds = pd.read_csv(dataDir + 'rcd_acc_eds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_eds = rcd_acc_eds[['agency_code', 'pct_eds']]\n",
    "\n",
    "#Pivot File - rcd_acc_elp\n",
    "rcd_acc_elp = PivotCsv(dataDir, 'rcd_acc_elp.csv',['pct'],'agency_code', ['subgroup'],'_ELP')\n",
    "\n",
    "#File - rcd_acc_essa_desig\n",
    "rcd_acc_essa_desig = pd.read_csv(dataDir + 'rcd_acc_essa_desig.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_essa_desig.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_gp\n",
    "rcd_acc_gp = pd.read_csv(dataDir + 'rcd_acc_gp.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_gp.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_irm\n",
    "rcd_acc_irm = PivotCsv(dataDir, 'rcd_acc_irm.csv',['pct_prof'],'agency_code', ['grade'],'gr_irm')\n",
    "\n",
    "#File - rcd_acc_lowperf\n",
    "rcd_acc_lowperf = pd.read_csv(dataDir + 'rcd_acc_lowperf.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_lowperf = rcd_acc_lowperf[['agency_code', 'lp_school','rlp_school','clpc_school']]\n",
    "\n",
    "#Pivot File - rcd_acc_ltg\n",
    "rcd_acc_ltg = PivotCsv(dataDir, 'rcd_acc_ltg.csv',['pct_met'],'agency_code', ['target'],'_LTG')\n",
    "\n",
    "#File - rcd_acc_ltg_detail\n",
    "rcd_acc_ltg_detail = pd.read_csv(dataDir + 'rcd_acc_ltg_detail.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_ltg_detail.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_mcr\n",
    "rcd_acc_mcr = PivotCsv(dataDir, 'rcd_acc_mcr.csv',['pct'],'agency_code', ['subgroup'],'_MCR')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_part = PivotCsv(dataDir, 'rcd_acc_part.csv',['pct_met'],'agency_code', ['target'],'_PART')\n",
    "\n",
    "#Pivot File - rcd_acc_part\n",
    "rcd_acc_part_detail = PivotCsv(dataDir, 'rcd_acc_part_detail.csv',['pct'],'agency_code', ['target','subgroup'],'_PART_DET')\n",
    "\n",
    "#Pivot File - rcd_acc_pc - WARNING 3323 columns!!! \n",
    "rcd_acc_pc = PivotCsv(dataDir, 'rcd_acc_pc.csv',['pct'],'agency_code', ['standard','subject','grade','subgroup'],'_PC')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_rta = PivotCsv(dataDir, 'rcd_acc_rta.csv',['pct'],'agency_code', ['metric'],'_RTA')\n",
    "\n",
    "#File - rcd_acc_spg1\n",
    "rcd_acc_spg1 = pd.read_csv(dataDir + 'rcd_acc_spg1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_spg1.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_spg2\n",
    "pivVals = ['aaa_score','awa_score','cgrs_score','elp_score','mcr_score','scgs_score','bi_score',\n",
    "           'ach_score','eg_status','eg_score','spg_score','spg_grade']\n",
    "           \n",
    "rcd_acc_spg2 = PivotCsv(dataDir, 'rcd_acc_spg2.csv',pivVals,'agency_code', ['subgroup'],'_SPG2')\n",
    "\n",
    "#Pivot File - rcd_acc_wk\n",
    "rcd_acc_wk = PivotCsv(dataDir, 'rcd_acc_wk.csv',['pct'],'agency_code', ['subgroup'],'_WK')\n",
    "\n",
    "#File - rcd_adm\n",
    "rcd_adm = pd.read_csv(dataDir + 'rcd_adm.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_adm.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_ap\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_ap = pd.read_csv(dataDir + 'rcd_ap.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ap.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_arts\n",
    "rcd_arts = pd.read_csv(dataDir + 'rcd_arts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_arts.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_att\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_att = pd.read_csv(dataDir + 'rcd_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_charter\n",
    "rcd_charter = PivotCsv(dataDir, 'rcd_charter.csv',['pct_enrolled'],'agency_code', ['home_lea','subgroup'],'_CHARTER')\n",
    "\n",
    "#Pivot File - rcd_chronic_absent\n",
    "rcd_chronic_absent = PivotCsv(dataDir, 'rcd_chronic_absent.csv',['pct'],'agency_code', ['subgroup'],'_CHRON_ABSENT')\n",
    "\n",
    "#Pivot File - rcd_college\n",
    "rcd_college = PivotCsv(dataDir, 'rcd_college.csv',['pct_enrolled'],'agency_code', ['status','subgroup'],'_COLLEGE')\n",
    "\n",
    "#File - rcd_courses1 - 2017 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_courses1 = pd.read_csv(dataDir + 'rcd_courses1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_courses1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_courses2\n",
    "rcd_courses2 = PivotCsv(dataDir, 'rcd_courses2.csv',['pct_ap','pct_ccp','pct_ib'],'agency_code', ['category_code','subgroup'],\n",
    "                        '_COURSES2')\n",
    "\n",
    "#Pivot File - rcd_cte_concentrators\n",
    "rcd_cte_concentrators = PivotCsv(dataDir, 'rcd_cte_concentrators.csv',['num_concentrators'],'agency_code',\n",
    "                                 ['career_cluster'],'')\n",
    "\n",
    "#File - rcd_cte_credentials\n",
    "rcd_cte_credentials = pd.read_csv(dataDir + 'rcd_cte_credentials.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_credentials.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_endorsement\n",
    "rcd_cte_endorsement = pd.read_csv(dataDir + 'rcd_cte_endorsement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_endorsement.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_enrollment\n",
    "rcd_cte_enrollment = pd.read_csv(dataDir + 'rcd_cte_enrollment.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_enrollment['cte_enrollment_pct'] = rcd_cte_enrollment['pct'] \n",
    "rcd_cte_enrollment.drop(['year','pct'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_dlmi\n",
    "rcd_dlmi = pd.read_csv(dataDir + 'rcd_dlmi.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_dlmi.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_effectiveness - 2017 Data\n",
    "rcd_effectiveness = PivotCsv(dataDir, 'rcd_effectiveness.csv',['pct_rating'],'agency_code', ['ee_standard','ee_rating'],'')\n",
    "\n",
    "#File - rcd_esea_att - 2015 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_esea_att = pd.read_csv(dataDir + 'rcd_esea_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_esea_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_experience\n",
    "expPivColumns = ['pct_experience_0','pct_experience_10','pct_experience_4',\n",
    "                 'pct_adv_degree','pct_turnover','total_class_teach','avg_class_teach']\n",
    "rcd_experience = PivotCsv(dataDir, 'rcd_experience.csv',expPivColumns,'agency_code', ['staff'],'Exp')\n",
    "\n",
    "#File - !!!DISTRICT LEVEL DATA!!!\n",
    "rcd_funds = pd.read_csv(dataDir + 'rcd_funds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_funds.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_hqt - !!!2016 DATA!!!\n",
    "rcd_hqt = PivotCsv(dataDir, 'rcd_hqt.csv',['highqual_class_pct'],'agency_code', ['category_code'],'')\n",
    "\n",
    "#File - rcd_ib\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_ib = pd.read_csv(dataDir + 'rcd_ib.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ib.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_improvement\n",
    "rcd_improvement = PivotCsv(dataDir, 'rcd_improvement.csv',['amount'],'agency_code', ['strategy'],'_Improve_Amt')\n",
    "\n",
    "#File - rcd_inc1\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_inc1 = pd.read_csv(dataDir + 'rcd_inc1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_inc1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_inc2 \n",
    "pivFields = ['iss_per1000','sts_per1000','lts_per1000',\n",
    "             'exp_per1000','crime_per1000','blhr_per1000',\n",
    "             'rplw_per1000','arre_per1000']\n",
    "rcd_inc2 = PivotCsv(dataDir, 'rcd_inc2.csv',pivFields,'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_licenses\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_licenses = pd.read_csv(dataDir + 'rcd_licenses.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_licenses.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_location\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_location = pd.read_csv(dataDir + 'rcd_location.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_location.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Pivot File - rcd_naep !!!NATIONAL & STATE LEVEL DATA!!!\n",
    "pivCols = ['grade','naep_subject','subgroup','Proficiency_level']\n",
    "rcd_naep = PivotCsv(dataDir, 'rcd_naep.csv',['percent_proficient'],'agency_code', pivCols,'_NAEP')\n",
    "\n",
    "#File - rcd_licenses\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_nbpts = pd.read_csv(dataDir + 'rcd_nbpts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_nbpts.drop(['year','category_code','total_nbpts_num'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_pk_enroll\n",
    "rcd_pk_enroll = PivotCsv(dataDir, 'rcd_pk_enroll.csv',['pct'],'agency_code', ['subgroup'],'_PK_ENROLL')\n",
    "\n",
    "#Pivot File - rcd_prin_demo - !!! District Level Data !!!\n",
    "rcd_prin_demo = PivotCsv(dataDir, 'rcd_prin_demo.csv',['pct_prin_demo'],'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_readiness\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_readiness = pd.read_csv(dataDir + 'rcd_readiness.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_readiness.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_sar\n",
    "rcd_sar = PivotCsv(dataDir, 'rcd_sar.csv',['avg_size'],'agency_code', ['grade_eoc'],'_SAR')\n",
    "\n",
    "#File - rcd_sat\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_sat = pd.read_csv(dataDir + 'rcd_sat.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_sat.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_welcome\n",
    "rcd_welcome = pd.read_csv(dataDir + 'rcd_welcome.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_welcome.drop(['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save All Flattened Files to \\\\Raw Datasets Directory\n",
    "**This code saves all the flattened file versions as .csv files in \\\\Raw Datasets\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2018/Raw Datasets/'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set dataDir back to the original value (one folder up from current location)\n",
    "import os \n",
    "dataDir = os.path.dirname(os.path.dirname(dataDir)) + '/'\n",
    "dataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "rcd_161, 644\n",
      "rcd_acc_aapart, 53\n",
      "rcd_acc_act, 742\n",
      "rcd_acc_awa, 688\n",
      "rcd_acc_cgr, 738\n",
      "rcd_acc_eds, 2761\n",
      "rcd_acc_elp, 1809\n",
      "rcd_acc_essa_desig, 2645\n",
      "rcd_acc_gp, 658\n",
      "rcd_acc_irm, 1276\n",
      "rcd_acc_lowperf, 2760\n",
      "rcd_acc_ltg, 2461\n",
      "rcd_acc_ltg_detail, 2631\n",
      "rcd_acc_mcr, 717\n",
      "rcd_acc_part, 2527\n",
      "rcd_acc_part_detail, 2527\n",
      "rcd_acc_pc, 2697\n",
      "rcd_acc_rta, 1576\n",
      "rcd_acc_spg1, 2584\n",
      "rcd_acc_spg2, 2538\n",
      "rcd_acc_wk, 517\n",
      "rcd_adm, 3197\n",
      "rcd_ap, 563\n",
      "rcd_arts, 2509\n",
      "rcd_att, 3115\n",
      "rcd_charter, 241\n",
      "rcd_chronic_absent, 2719\n",
      "rcd_college, 690\n",
      "rcd_courses1, 773\n",
      "rcd_courses2, 636\n",
      "rcd_cte_concentrators, 492\n",
      "rcd_cte_credentials, 436\n",
      "rcd_cte_endorsement, 537\n",
      "rcd_cte_enrollment, 1184\n",
      "rcd_dlmi, 2723\n",
      "rcd_effectiveness, 2724\n",
      "rcd_esea_att, 2700\n",
      "rcd_experience, 2758\n",
      "rcd_funds, 292\n",
      "rcd_hqt, 2697\n",
      "rcd_ib, 51\n",
      "rcd_improvement, 19\n",
      "rcd_inc1, 3097\n",
      "rcd_inc2, 2792\n",
      "rcd_licenses, 3121\n",
      "rcd_location, 2759\n",
      "rcd_naep, 2\n",
      "rcd_nbpts, 3124\n",
      "rcd_pk_enroll, 988\n",
      "rcd_prin_demo, 116\n",
      "rcd_readiness, 1323\n",
      "rcd_sar, 2630\n",
      "rcd_sat, 613\n",
      "rcd_welcome, 1311\n"
     ]
    }
   ],
   "source": [
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "for fileName in rcdFileNames:\n",
    "    eval(fileName).to_csv(dataDir + 'Flattened Datasets/' + fileName + '.csv', sep=',', index=False)\n",
    "    print(fileName + ', ' + str(len(eval(fileName).index)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original Statistical Profiles Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "import io\n",
    "import requests\n",
    "\n",
    "url='http://apps.schools.nc.gov/ords/f?p=145:221::CSV::::'\n",
    "statProfPath = dataDir + 'SRC_Datasets/' + 'ec_pupils.csv'\n",
    "\n",
    "#Passing this URL directly into pd.read_csv() threw HTTP errors - This is my workaround\n",
    "s = requests.get(url).content\n",
    "ec_pupils = pd.read_csv(io.StringIO(s.decode('utf-8')), low_memory=False\n",
    "                        , dtype={'LEA': object,'School': object})\n",
    "\n",
    "#Rename year for consistency\n",
    "ec_pupils.rename({'Year':'year'}, axis=1, inplace=True)\n",
    "\n",
    "#Create agency_code from LEA and School code as an index\n",
    "ec_pupils['agency_code'] = ec_pupils['LEA'] + ec_pupils['School']\n",
    "\n",
    "#Filter to 2018 school year (There is already 2019 school year data in this file)\n",
    "#ec_pupils = ec_pupils[ec_pupils.year == schoolYear]\n",
    "\n",
    "#Some schools are missing race data.  Get the most recent year of data available for each agency code\n",
    "ec_pupils = ec_pupils.sort_values(by=['agency_code', 'year'])\n",
    "ec_pupils = ec_pupils.drop_duplicates(subset=[\"agency_code\"], keep=\"last\")\n",
    "\n",
    "#Save the original data to the source datasets folder \n",
    "ec_pupils.to_csv(statProfPath, sep=',', index=False)\n",
    "\n",
    "#Get data for the most recent school year\n",
    "#CleanUpRcdFiles(statProfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flattened Statistical Profiles with Racial Composition Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "ec_pupils_pct, 2558\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "# Statistical Profiles - Student Body Racial Compositions at the School Level Reshape\n",
    "#\n",
    "# Statistical Profiles data are already one record per public school but must be converted to percentages\n",
    "# Creates a new dataset - ec_pupils_pct.csv\n",
    "#\n",
    "#***********************************************************************\n",
    "\n",
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "ec_pupils = pd.read_csv(statProfPath, low_memory=False, dtype={'agency_code': object})\n",
    "\n",
    "#Create Racial Composition summary variables\n",
    "ec_pupils['Indian'] = ec_pupils['Indian Male'] + ec_pupils['Indian Female']\n",
    "ec_pupils['Asian'] = ec_pupils['Asian Male'] + ec_pupils['Asian Female']\n",
    "ec_pupils['Hispanic'] = ec_pupils['Hispanic Male'] + ec_pupils['Hispanic Female']\n",
    "ec_pupils['Black'] = ec_pupils['Black Male'] + ec_pupils['Black Female']\n",
    "ec_pupils['White'] = ec_pupils['White Male'] + ec_pupils['White Female']\n",
    "ec_pupils['Pacific Island'] = ec_pupils['Pacific Island Male'] + ec_pupils['Pacific Island Female']\n",
    "ec_pupils['Two or  More'] = ec_pupils['Two or  More Male'] + ec_pupils['Two or  More Female']\n",
    "\n",
    "#The original total field is corrupted with non-printable characters and will not convert to int or float \n",
    "ec_pupils.drop(['Total'], axis=1, inplace=True)\n",
    "#Create a new totals field by summing race composition fields\n",
    "ec_pupils['Total'] = ec_pupils['Indian'] + ec_pupils['Asian'] + \\\n",
    "                     ec_pupils['Hispanic'] + ec_pupils['Black'] + \\\n",
    "                     ec_pupils['White'] + ec_pupils['Pacific Island'] + ec_pupils['Two or  More']\n",
    "#Convert Totals to float64 for division later\n",
    "ec_pupils['Total'] = ec_pupils['Total'].astype(np.float64)\n",
    "\n",
    "#Create Minority summary variables \n",
    "ec_pupils['Minority Male'] = ec_pupils['Indian Male'] + ec_pupils['Asian Male'] \\\n",
    "                           + ec_pupils['Hispanic Male'] + ec_pupils['Black Male'] \\\n",
    "                           + ec_pupils['Pacific Island Male'] + ec_pupils['Two or  More Male'] \n",
    "ec_pupils['Minority Female'] = ec_pupils['Indian Female'] + ec_pupils['Asian Female'] \\\n",
    "                           + ec_pupils['Hispanic Female'] + ec_pupils['Black Female'] \\\n",
    "                           + ec_pupils['Pacific Island Female'] + ec_pupils['Two or  More Female']\n",
    "ec_pupils['Minority'] = ec_pupils['Minority Male'] + ec_pupils['Minority Female']\n",
    "\n",
    "#Create Student Body Racial Composition PERCENTAGES at the School Level\n",
    "ec_pupils_pct = pd.DataFrame({'agency_code'   : ec_pupils['agency_code']\n",
    "                            , 'School Name' : ec_pupils['___School Name___']\n",
    "                            , 'IndianPct'   : ec_pupils['Indian'] / ec_pupils['Total']  \n",
    "                            , 'AsianPct'    : ec_pupils['Asian'] / ec_pupils['Total']\n",
    "                            , 'HispanicPct' : ec_pupils['Hispanic'] / ec_pupils['Total']\n",
    "                            , 'BlackPct'    : ec_pupils['Black'] / ec_pupils['Total']\n",
    "                            , 'WhitePct'    : ec_pupils['White'] / ec_pupils['Total']\n",
    "                            , 'PacificIslandPct': ec_pupils['Pacific Island'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMorePct': ec_pupils['Two or  More'] / ec_pupils['Total']\n",
    "                            , 'MinorityPct' : ec_pupils['Minority'] / ec_pupils['Total']\n",
    "                            \n",
    "                              \n",
    "                            , 'IndianMalePct'   : ec_pupils['Indian Male'] / ec_pupils['Total']  \n",
    "                            , 'AsianMalePct'    : ec_pupils['Asian Male'] / ec_pupils['Total']\n",
    "                            , 'HispanicMalePct' : ec_pupils['Hispanic Male'] / ec_pupils['Total']\n",
    "                            , 'BlackMalePct'    : ec_pupils['Black Male'] / ec_pupils['Total']\n",
    "                            , 'WhiteMalePct'    : ec_pupils['White Male'] / ec_pupils['Total']\n",
    "                            , 'PacificIslandMalePct': ec_pupils['Pacific Island Male'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMoreMalePct': ec_pupils['Two or  More Male'] / ec_pupils['Total']  \n",
    "                            , 'MinorityMalePct' : ec_pupils['Minority Male'] / ec_pupils['Total']\n",
    "                                                          \n",
    "                            , 'IndianFemalePct'   : ec_pupils['Indian Female'] / ec_pupils['Total']  \n",
    "                            , 'AsianFemalePct'    : ec_pupils['Asian Female'] / ec_pupils['Total']\n",
    "                            , 'HispanicFemalePct' : ec_pupils['Hispanic Female'] / ec_pupils['Total']\n",
    "                            , 'BlackFemalePct'    : ec_pupils['Black Female'] / ec_pupils['Total']\n",
    "                            , 'WhiteFemalePct'    : ec_pupils['White Female'] / ec_pupils['Total']\n",
    "                            , 'MinorityFemalePct' : ec_pupils['Minority Female'] / ec_pupils['Total'] \n",
    "                            , 'PacificIslandFemalePct': ec_pupils['Pacific Island Female'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMoreFemalePct': ec_pupils['Two or  More Female'] / ec_pupils['Total']\n",
    "                             })\n",
    "\n",
    "#Save the flattened racial composition percentage data to disk \n",
    "ec_pupils_pct.to_csv(dataDir + 'Flattened Datasets/' + 'ec_pupils_pct.csv', sep=',', index=False)\n",
    "\n",
    "#Print file details\n",
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "print('ec_pupils_pct' + ', ' + str(len(ec_pupils_pct.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rcd_pk_enroll.csv Counts Flattened File\n",
    "* The rcd_pk_enroll.csv percentages always = 1 for the _ALL subgroup (only shows distribution of race)\n",
    "* Adding actual PK enrollment counts to track PK enrollment growth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcd_pk_enroll_ct, RangeIndex(start=0, stop=988, step=1)\n"
     ]
    }
   ],
   "source": [
    "#Pivot File - rcd_pk_enroll\n",
    "rcd_pk_enroll_ct = PivotCsv(dataDir, 'SRC_Datasets/rcd_pk_enroll.csv',['count'],'agency_code', ['subgroup'],'_PK_ENROLL')\n",
    "\n",
    "rcd_pk_enroll_ct.to_csv(dataDir + 'Flattened Datasets/' + 'rcd_pk_enroll_ct.csv', sep=',', index=False)\n",
    "print('rcd_pk_enroll_ct' + ', ' + str(rcd_pk_enroll_ct.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
